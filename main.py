from fastapi import FastAPI, Query
from pydantic import BaseModel
import requests
from bs4 import BeautifulSoup

# ====== –î–û–ë–ê–í–õ–ï–ù–û ======
import concurrent.futures
from urllib.parse import quote
import re
from typing import List, Dict

# –û–±—â–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏, —á—Ç–æ–±—ã –º–µ–Ω—å—à–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞–ª–∏
DEFAULT_HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/127.0.0.0 Safari/537.36"
    ),
    "Accept-Language": "ru,en;q=0.9,zh;q=0.8",
    "Cache-Control": "no-cache",
    "Pragma": "no-cache",
}
SESSION = requests.Session()
SESSION.headers.update(DEFAULT_HEADERS)
TIMEOUT = 12
MAX_WORKERS = 16
MAX_RESULTS = 500
# ====== /–î–û–ë–ê–í–õ–ï–ù–û ======


app = FastAPI(
    title="DI-Agent SDK",
    description="–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤ –ö–∏—Ç–∞—è",
    version="1.0.2"
)

# üîπ –ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
class SearchRequest(BaseModel):
    query: str

# üîπ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã
def safe_request(url):
    try:
        r = SESSION.get(url, timeout=TIMEOUT)
        if r.status_code == 200:
            return r.text
        else:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ {r.status_code} –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}")
            return ""
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}: {e}")
        return ""

# üîπ –ü–∞—Ä—Å–∏–Ω–≥ —Å–ø–∏—Å–∫–∞ –∫–æ–º–ø–∞–Ω–∏–π (—Ç–≤–æ–π –∏—Å—Ö–æ–¥–Ω—ã–π –ø–∞—Ä—Å–µ—Ä ‚Äî –ù–ï –¢–†–û–ì–ê–õ)
def parse_suppliers(html, selectors, source):
    if not html:
        return []

    soup = BeautifulSoup(html, "lxml")
    titles, links = [], []

    for sel in selectors:
        for t in soup.select(sel["title"]):
            title = t.get_text(strip=True)
            if title and title not in titles:
                titles.append(title)
        for a in soup.select(sel["link"]):
            href = a.get("href")
            if href and href not in links:
                links.append(href)

    suppliers = []
    for i in range(min(5, len(titles))):
        suppliers.append({
            "–ù–∞–∑–≤–∞–Ω–∏–µ": titles[i],
            "–°—Å—ã–ª–∫–∞": links[i] if i < len(links) else "N/A",
            "–ò—Å—Ç–æ—á–Ω–∏–∫": source
        })
    return suppliers

# ====== –î–û–ë–ê–í–õ–ï–ù–û: –≥–∏–±–∫–∏–π –ø–∞—Ä—Å–µ—Ä –ø–æ–¥ —Ä–∞–∑–Ω—ã–µ —Å–∞–π—Ç—ã ======
GENERIC_SELECTORS = [
    {"title": "h2 a", "link": "h2 a"},
    {"title": ".title a", "link": ".title a"},
    {"title": ".product-title a", "link": ".product-title a"},
    {"title": ".company-name a", "link": ".company-name a"},
    {"title": "a.gs-product-card__name", "link": "a.gs-product-card__name"},
    {"title": ".organic-gallery-title a", "link": ".organic-gallery-title a"},
    {"title": "h3 a", "link": "h3 a"},
    {"title": "a", "link": "a"},
]

def parse_flexible(html: str, source: str) -> List[Dict]:
    if not html:
        return []
    soup = BeautifulSoup(html, "lxml")
    results: List[Dict] = []
    seen = set()

    # –ü—Ä–æ–±—É–µ–º –Ω–∞–±–æ—Ä –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤
    for sel in GENERIC_SELECTORS:
        for a in soup.select(sel["link"]):
            href = a.get("href", "").strip()
            title = a.get_text(" ", strip=True)
            if not href or not title:
                continue
            if href.startswith("//"):
                href = "https:" + href
            if not href.startswith("http"):
                continue
            key = (title, href)
            if key in seen:
                continue
            seen.add(key)
            results.append({
                "–ù–∞–∑–≤–∞–Ω–∏–µ": title[:200],
                "–°—Å—ã–ª–∫–∞": href,
                "–ò—Å—Ç–æ—á–Ω–∏–∫": source
            })
            if len(results) >= 50:
                break
        if len(results) >= 50:
            break
    return results
# ====== /–î–û–ë–ê–í–õ–ï–ù–û ======


@app.get("/")
def root():
    return {
        "status": "‚úÖ DI-Agent SDK –∞–∫—Ç–∏–≤–µ–Ω",
        "docs": "/docs",
        "search_example": "/search?q=–õ–°–¢–ö"
    }


# ====== –î–û–ë–ê–í–õ–ï–ù–û: —Å–ø–∏—Å–æ–∫ 70+ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ ======
# –ö–∞–∂–¥–æ–º—É —Å–∞–π—Ç—É ‚Äî URL-—à–∞–±–ª–æ–Ω —Å {q}. –ï—Å–ª–∏ —Å–∞–π—Ç –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∫–∏—Ä–∏–ª–ª–∏—Ü—É, –º—ã –ø–µ—Ä–µ–≤–µ–¥—ë–º.
SOURCES: Dict[str, str] = {
    # –ö—Ä—É–ø–Ω—ã–µ B2B
    "Alibaba": "https://www.alibaba.com/trade/search?fsb=y&IndexArea=product_en&searchText={q}",
    "Made-in-China": "https://www.made-in-china.com/search?word={q}",
    "GlobalSources": "https://www.globalsources.com/searchList?query={q}",
    "1688 (via Baidu)": "https://www.baidu.com/s?wd={q}+site:1688.com",
    "HKTDC": "https://sourcing.hktdc.com/Search-Product?keyword={q}",
    "ECVV": "https://www.ecvv.com/catalog/{q}.html",
    "ECER": "https://www.ecer.com/search?kw={q}",
    "HC360": "https://s.hc360.com/seller/search.html?kwd={q}",
    "DHgate": "https://www.dhgate.com/wholesale/search.do?act=search&searchkey={q}",
    "YiwuGo": "https://en.yiwugo.com/search/{q}.html",
    "TradeKey": "https://www.tradekey.com/suppliers/{q}.html",
    "ExportHub": "https://www.exporthub.com/search?q={q}",
    "TradeWheel": "https://www.tradewheel.com/search/{q}/",
    "En.China.cn": "https://en.china.cn/search.html?searchKey={q}",
    "Hisupplier": "https://www.hisupplier.com/wholesale/{q}/",
    "Epoly": "https://www.etwinternational.com/search?kw={q}",
    "Globalspec": "https://www.globalspec.com/Search/Results?query={q}",
    "ThomasNet": "https://www.thomasnet.com/search.html?what={q}",
    "Kompass": "https://us.kompass.com/en/searchCompanies/companies/{q}/",
    "Qcc (companies)": "https://www.qcc.com/web/search?key={q}",
    "Tianyancha": "https://www.tianyancha.com/search?key={q}",

    # –ú–∞—Ä–∫–µ—Ç—ã –ö–∏—Ç–∞—è
    "JD": "https://search.jd.com/Search?keyword={q}",
    "Taobao": "https://s.taobao.com/search?q={q}",
    "Pinduoduo": "https://mobile.yangkeduo.com/search_result.html?search_key={q}",

    # –ü—Ä–æ—Ñ. –∫–∞—Ç–∞–ª–æ–≥–∏/–±–∏—Ä–∂–∏/—Ç–µ–Ω–¥–µ—Ä—ã
    "MFG": "https://www.mfg.com/en/search/?q={q}",
    "AliExpress B2B": "https://www.aliexpress.com/wholesale?SearchText={q}",
    "Globalsources Verified": "https://www.globalsources.com/searchList?query={q}&verifiedSupplier=true",
    "Baidu Baike": "https://baike.baidu.com/search?word={q}",
    "Sohu": "https://www.sogou.com/web?query={q}",
    "Bing China": "https://cn.bing.com/search?q={q}",
    "Google (backup)": "https://www.google.com/search?q={q}",

    # –ï—â—ë B2B/–∞–≥—Ä–µ–≥–∞—Ç–æ—Ä—ã (–¥–æ–±–∞–≤–ª–µ–Ω–æ, —á—Ç–æ–±—ã –±—ã–ª–æ 70+)
    "E-WorldTrade": "https://www.eworldtrade.com/search/{q}/",
    "China.cn": "https://www.china.cn/search.html?searchKey={q}",
    "B2BManufactures": "https://www.manufacturers.com.tw/search.php?words={q}",
    "Maker-In-China": "https://www.maker-in-china.com/search.html?kw={q}",
    "Manufacturers Directory": "https://www.manufacturersdirectory.com/search?query={q}",
    "IndiaMART": "https://dir.indiamart.com/search.mp?ss={q}",
    "TradeIndia": "https://www.tradeindia.com/search.html?search_text={q}",
    "ECPlaza": "https://www.ecplaza.net/search/1?keyword={q}",
    "YellowPages": "https://www.yellowpages.com/search?search_terms={q}",
    "B2Brazil": "https://b2brazil.com/hotsite/search?term={q}",
    "B2BMit": "https://www.b2bmit.com/search.html?q={q}",
    "Globalsources Suppliers": "https://www.globalsources.com/suppliers?query={q}",
    "AliBaba Suppliers": "https://www.alibaba.com/company_directory/search/{q}.html",
    "CantonFair": "https://www.cantonfair.org.cn/en-US/search?key={q}",
    "HKTDC Suppliers": "https://sourcing.hktdc.com/en/supplier-search/{q}",
    "Europages": "https://www.europages.com/companies/{q}.html",
    "Kompass CN": "https://cn.kompass.com/en/searchCompanies/companies/{q}/",
    "Made-in-China Companies": "https://www.made-in-china.com/company-search/?word={q}",
    "MIC Verified": "https://www.made-in-china.com/company-search/?word={q}&select=verified",
    "GlobalMarket": "https://www.globalmarket.com/search/{q}.html",
    "EtradeAsia": "https://www.etradeasia.com/search?keyword={q}",
    "Mawoo": "https://www.made-in-asia.net/search?kw={q}",
    "EveryChina": "https://www.everychina.com/search.html?kw={q}",
    "ChinaProducts": "https://www.china-products-manufacturers.com/search?keyword={q}",
    "Crov": "https://www.crov.com/search?q={q}",
    "DiyTrade": "https://www.diytrade.com/china/search/products.do?keyword={q}",
    "Okchem": "https://www.okchem.com/search?keyword={q}",
    "ChemNet": "https://www.chemnet.com/global/en/search.html?keyword={q}",
    "Food2China": "https://www.food2china.com/search?keyword={q}",
    "PharmaSources": "https://www.pharmasources.com/searchResult?keyword={q}",
    "MedicaTradeFair": "https://www.medica-tradefair.com/vis/v1/en/search?term={q}",
    "HKTDC Products": "https://sourcing.hktdc.com/Search-Product?keyword={q}&productonly=1",
    "Xiaohongshu": "https://www.xiaohongshu.com/search_result?keyword={q}",
    "Weixin": "https://weixin.sogou.com/weixin?type=2&query={q}",
    "Bilibili": "https://search.bilibili.com/all?keyword={q}",
    "Weibo": "https://s.weibo.com/weibo?q={q}",
    "LinkedIn": "https://www.linkedin.com/search/results/companies/?keywords={q}",
    "Pinterest": "https://www.pinterest.com/search/pins/?q={q}",
    "YouTube": "https://www.youtube.com/results?search_query={q}"
}

# –¢–æ—á–µ—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–ª—é—á–µ–≤—ã—Ö –ø–ª–æ—â–∞–¥–æ–∫ (–æ—Å—Ç–∞–ª—å–Ω—ã–µ ‚Äî –≥–∏–±–∫–∏–π –ø–∞—Ä—Å–µ—Ä)
SITE_SELECTORS: Dict[str, List[Dict[str, str]]] = {
    "Alibaba": [{"title": ".organic-gallery-title", "link": ".organic-gallery-title a"}],
    "Made-in-China": [{"title": ".company-name a", "link": ".company-name a"}],
    "GlobalSources": [{"title": "a.gs-product-card__name", "link": "a.gs-product-card__name"}],
    "1688 (via Baidu)": [{"title": "h3.t a", "link": "h3.t a"}],
    "HKTDC": [{"title": ".product-name a, .cmpny-name a", "link": ".product-name a, .cmpny-name a"}],
    "ECER": [{"title": ".pro-title a, .supplier-name a", "link": ".pro-title a, .supplier-name a"}],
    "ECVV": [{"title": ".pro-title a, .company a", "link": ".pro-title a, .company a"}],
    "HC360": [{"title": ".search-list .title a", "link": ".search-list .title a"}],
    "DHgate": [{"title": ".item-title a", "link": ".item-title a"}],
    "YiwuGo": [{"title": ".title a", "link": ".title a"}],
    "TradeWheel": [{"title": ".item-title a", "link": ".item-title a"}],
    "ExportHub": [{"title": "h4.media-heading a", "link": "h4.media-heading a"}],
}

# –ë—ã—Å—Ç—Ä—ã–π –ø–µ—Ä–µ–≤–æ–¥ —á–∞—Å—Ç—ã—Ö —Ä—É—Å—Å–∫–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –≤ –∞–Ω–≥–ª-–∑–∞–ø—Ä–æ—Å—ã
def normalize_query(q: str) -> str:
    if re.search(r"[–ê-–Ø–∞-—è–Å—ë]", q):
        low = q.lower()
        mapping = {
            "—Ñ–∏–±—Ä–æ—Ü–µ–º": "fiber cement panels",
            "–ø–µ–Ω–æ–±–µ—Ç–æ–Ω": "foam concrete",
            "–ª—Å—Ç–∫": "light gauge steel frame",
            "—Å—ç–Ω–¥–≤–∏—á": "sandwich panels",
            "–æ—Ü–∏–Ω–∫–æ–≤–∞–Ω": "galvanized steel",
            "–∞–ª—é–∫–æ–±–æ–Ω–¥": "aluminum composite panel",
        }
        for k, v in mapping.items():
            if k in low:
                return v
    return q

def _fetch_one(name: str, url: str) -> List[Dict]:
    html = safe_request(url)
    # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–ø–µ—Ü-—Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Å–∞–π—Ç–∞ ‚Äî –ø—Ä–∏–º–µ–Ω—è–µ–º —Ç–≤–æ–π –∏—Å—Ö–æ–¥–Ω—ã–π –ø–∞—Ä—Å–µ—Ä
    if name in SITE_SELECTORS:
        return parse_suppliers(html, SITE_SELECTORS[name], name)
    # –ò–Ω–∞—á–µ ‚Äî –≥–∏–±–∫–∏–π –ø–∞—Ä—Å–µ—Ä
    return parse_flexible(html, name)

def extended_collect(query: str) -> List[Dict]:
    q_norm = normalize_query(query)
    q_enc = quote(q_norm)

    tasks = {}
    results: List[Dict] = []

    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        for name, tmpl in SOURCES.items():
            url = tmpl.format(q=q_enc)
            tasks[ex.submit(_fetch_one, name, url)] = name

        for fut in concurrent.futures.as_completed(tasks):
            name = tasks[fut]
            try:
                chunk = fut.result() or []
                if chunk:
                    print(f"‚úÖ {name}: {len(chunk)}")
                results.extend(chunk)
            except Exception as e:
                print(f"‚ùå {name}: {e}")

    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ –ø–æ–ª–Ω–æ–π —Å—Å—ã–ª–∫–µ
    uniq, seen = [], set()
    for item in results:
        link = (item.get("–°—Å—ã–ª–∫–∞") or "").strip()
        if not link or link in seen:
            continue
        seen.add(link)
        uniq.append(item)
        if len(uniq) >= MAX_RESULTS:
            break

    return uniq
# ====== /–î–û–ë–ê–í–õ–ï–ù–û ======


# üîπ –û–ë–ù–û–í–õ–Å–ù–ù–´–ô /search: —Å–Ω–∞—á–∞–ª–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–±–æ—Ä (70+),
#    –µ—Å–ª–∏ –ø—É—Å—Ç–æ ‚Äî —Ç–≤–æ–π –∏—Å—Ö–æ–¥–Ω—ã–π –±–ª–æ–∫ (4 –ø–ª–æ—â–∞–¥–∫–∏)
@app.get("/search")
def search(q: str = Query(..., description="–í–≤–µ–¥–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")):
    print(f"üîç –í—ã–ø–æ–ª–Ω—è—é –ø–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {q}")

    # 1) –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–±—Ä–∞—Ç—å –º–∞–∫—Å–∏–º—É–º
    big = extended_collect(q)
    if big:
        return {
            "status": "ok",
            "query": q,
            "count": len(big),
            "results": big[:MAX_RESULTS]
        }

    # 2) –§–æ–ª–±—ç–∫ ‚Äî —Ç–≤–æ—è –∏—Å—Ö–æ–¥–Ω–∞—è –ª–æ–≥–∏–∫–∞ (–ù–ï –£–î–ê–õ–Ø–õ)
    results = []

    html = safe_request(f"https://www.alibaba.com/trade/search?fsb=y&IndexArea=product_en&searchText={quote(normalize_query(q))}")
    results += parse_suppliers(html, [{"title": "h2.title, .organic-gallery-title", "link": "h2.title a, .organic-gallery-title a"}], "Alibaba")

    html = safe_request(f"https://www.made-in-china.com/search?word={quote(normalize_query(q))}")
    results += parse_suppliers(html, [{"title": ".company-name a", "link": ".company-name a"}], "Made-in-China")

    html = safe_request(f"https://www.globalsources.com/searchList?query={quote(normalize_query(q))}")
    results += parse_suppliers(html, [{"title": "a.gs-product-card__name", "link": "a.gs-product-card__name"}], "GlobalSources")

    html = safe_request(f"https://www.baidu.com/s?wd={quote(normalize_query(q))}+site:1688.com")
    results += parse_suppliers(html, [{"title": "h3.t a", "link": "h3.t a"}], "1688")

    if not results:
        return {"status": "error", "query": q, "results": []}

    return {
        "status": "ok",
        "query": q,
        "count": len(results),
        "results": results[:50]
    }

# üîπ –î–û–ë–ê–í–õ–ï–ù–û: –ø—Ä—è–º–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Å–±–æ—Ä–∞ (—É–¥–æ–±–Ω–æ –¥–ª—è GPT)
@app.get("/search_all")
def search_all(q: str = Query(..., description="–ü–æ–ª–Ω—ã–π —Å–±–æ—Ä –ø–æ 70+ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º")):
    data = extended_collect(q)
    return {
        "status": "ok" if data else "error",
        "query": q,
        "count": len(data),
        "results": data[:MAX_RESULTS]
    }