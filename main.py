from fastapi import FastAPI, Query
from pydantic import BaseModel
import requests
from bs4 import BeautifulSoup

app = FastAPI(
    title="DI-Agent SDK",
    description="–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤ –ö–∏—Ç–∞—è",
    version="1.0.2"
)

# üîπ –ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
class SearchRequest(BaseModel):
    query: str

# üîπ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã
def safe_request(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        r = requests.get(url, headers=headers, timeout=10)
        if r.status_code == 200:
            return r.text
        else:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ {r.status_code} –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}")
            return ""
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}: {e}")
        return ""

# üîπ –ü–∞—Ä—Å–∏–Ω–≥ —Å–ø–∏—Å–∫–∞ –∫–æ–º–ø–∞–Ω–∏–π
def parse_suppliers(html, selectors, source):
    if not html:
        return []

    soup = BeautifulSoup(html, "lxml")
    titles, links = [], []

    for sel in selectors:
        for t in soup.select(sel["title"]):
            title = t.get_text(strip=True)
            if title and title not in titles:
                titles.append(title)
        for a in soup.select(sel["link"]):
            href = a.get("href")
            if href and href not in links:
                links.append(href)

    suppliers = []
    for i in range(min(5, len(titles))):
        suppliers.append({
            "–ù–∞–∑–≤–∞–Ω–∏–µ": titles[i],
            "–°—Å—ã–ª–∫–∞": links[i] if i < len(links) else "N/A",
            "–ò—Å—Ç–æ—á–Ω–∏–∫": source
        })
    return suppliers


@app.get("/")
def root():
    return {
        "status": "‚úÖ DI-Agent SDK –∞–∫—Ç–∏–≤–µ–Ω",
        "docs": "/docs",
        "search_example": "/search?q=–õ–°–¢–ö"
    }


@app.get("/search")
def search(q: str = Query(..., description="–í–≤–µ–¥–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")):
    print(f"üîç –í—ã–ø–æ–ª–Ω—è—é –ø–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {q}")

    results = []

    # üî∏ Alibaba
    html = safe_request(f"https://www.alibaba.com/trade/search?fsb=y&IndexArea=product_en&searchText={q}")
    results += parse_suppliers(html, [{"title": "h2.title", "link": "h2.title a"}], "Alibaba")

    # üî∏ Made-in-China
    html = safe_request(f"https://www.made-in-china.com/search?word={q}")
    results += parse_suppliers(html, [{"title": ".company-name a", "link": ".company-name a"}], "Made-in-China")

    # üî∏ GlobalSources
    html = safe_request(f"https://www.globalsources.com/searchList?query={q}")
    results += parse_suppliers(html, [{"title": "a.gs-product-card__name", "link": "a.gs-product-card__name"}], "GlobalSources")

    # üî∏ 1688 (—á–µ—Ä–µ–∑ Baidu)
    html = safe_request(f"https://www.baidu.com/s?wd={q}+site:1688.com")
    results += parse_suppliers(html, [{"title": "h3.t", "link": "h3.t a"}], "1688")

    if not results:
        return {"status": "‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö", "query": q, "results": []}

    return {
        "status": "‚úÖ –£—Å–ø–µ—à–Ω–æ",
        "query": q,
        "count": len(results),
        "results": results[:5]
    }
